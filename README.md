# Projeto FusÃ£o Digital â€“ Arquitetura e Engenharia de Dados & BI

## ğŸ“Œ Contexto
Com a fusÃ£o entre duas empresas que operavam em infraestruturas distintas (on-premise e cloud), surgiu a necessidade de integrar os dados de vendas em uma base centralizada, confiÃ¡vel e padronizada, viabilizando anÃ¡lises consolidadas e suporte Ã  tomada de decisÃ£o estratÃ©gica.

---

## ğŸ¯ Objetivo
Integrar, tratar e disponibilizar dados de vendas de duas empresas por meio de uma pipeline automatizada, possibilitando a criaÃ§Ã£o de dashboards unificados para as Ã¡reas comercial e executiva.

---

## ğŸ—‚ï¸ Fonte dos Dados
- Dados de vendas de duas empresas distintas  
- Origem: SQL Server (on-premise) e PostgreSQL (AWS RDS)  
- Dados integrados, tratados e padronizados em ambiente cloud  

---

## ğŸ“š DocumentaÃ§Ã£o do Projeto
A documentaÃ§Ã£o detalhada do projeto estÃ¡ disponÃ­vel nos arquivos abaixo:

- [01 â€“ Contexto do Desafio](docs/01-contexto-do-desafio.md)
- [02 â€“ Arquitetura da SoluÃ§Ã£o](docs/02-arquitetura-da-solucao.md)
- [03 â€“ Modelagem de Dados](docs/03-modelagem-de-dados.md)
- [04 â€“ Desenvolvimento da Pipeline](docs/04-desenvolvimento.md)
- [05 â€“ Streaming e Processamento](docs/05-processamento-com-spark.md)
- [06 â€“ ImplantaÃ§Ã£o e ExecuÃ§Ã£o](docs/06-implantacao-e-execucao.md)

---

## ğŸ”§ Arquitetura e Desenvolvimento
- Pipeline de dados automatizada utilizando **Apache Airflow**
- ExecuÃ§Ã£o em ambiente **Docker Compose**
- Processos de ETL organizados em camadas **Bronze, Silver e Gold**
- ExportaÃ§Ã£o dos dados tratados para consumo analÃ­tico

---

## ğŸ” ELT com Python e Docker

O projeto utiliza uma abordagem de **ELT (Extract, Load, Transform)**, na qual os dados sÃ£o inicialmente extraÃ­dos e carregados, e posteriormente transformados utilizando scripts em Python.

### Etapas do ELT
- **Extract:** leitura dos dados de vendas das fontes de origem
- **Load:** persistÃªncia dos dados brutos na camada *Raw*
- **Transform:** aplicaÃ§Ã£o de regras de negÃ³cio e geraÃ§Ã£o dos dados tratados nas camadas *Processed / Analytics*

Os processos sÃ£o executados em ambiente containerizado com **Docker Compose**, garantindo padronizaÃ§Ã£o e reprodutibilidade do ambiente.

### IntegraÃ§Ã£o com Airflow
O Apache Airflow Ã© responsÃ¡vel por orquestrar as etapas do ELT, controlando dependÃªncias, agendamento e monitoramento da pipeline.


## ğŸ“Š AnÃ¡lise e VisualizaÃ§Ã£o
- Modelagem dos dados voltada para anÃ¡lise
- CriaÃ§Ã£o de mÃ©tricas e KPIs de vendas
- Desenvolvimento de dashboards interativos no **Power BI**

---

## ğŸ’¡ Principais Insights
- VisÃ£o consolidada de vendas pÃ³s-fusÃ£o
- EliminaÃ§Ã£o de inconsistÃªncias entre bases de dados
- Apoio Ã  tomada de decisÃ£o com dados centralizados e confiÃ¡veis

---

## ğŸš€ PrÃ³ximos Passos
- EvoluÃ§Ã£o do monitoramento com ferramentas como **Grafana**
- ImplementaÃ§Ã£o de versionamento de dados
- InclusÃ£o de novas fontes e mÃ©tricas analÃ­ticas

---

## ğŸ§± Arquitetura da SoluÃ§Ã£o
![Arquitetura](images/arquitetura_pipeline.png)

## âš™ï¸ OrquestraÃ§Ã£o com Apache Airflow
![DAG Airflow](images/airflow_dag.jpg)

## ğŸ“Š Dashboard Power BI
![Dashboard](images/Dashboard.png)
